{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import dataretrieval.nwis as nwis\n",
    "from datetime import date, timedelta\n",
    "import pylab\n",
    "from scipy import stats\n",
    "from pylr2 import regress2\n",
    "import pymannkendall as mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = \"/Volumes/GoogleDrive/My Drive/Chapter2_mechanisms_forest_water_cycling\"\n",
    "sbr_ref_combo_diss = gpd.read_file(os.path.join(home, \"Data\", \"Catchments\", \"Reference\", \"gages_ii\",\"reference_keep.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recession_df(gage, w, C):\n",
    "    # gage= usgs gage id \n",
    "    # w is the streamflow precision thredhold \n",
    "    # C is a scalar that we multiply by w. C >= 1\n",
    "    \n",
    "    site = gage\n",
    "\n",
    "    # Download the streamflow data\n",
    "    streamflow_df = nwis.get_record(sites=site, service = 'dv', start = '1984-01-01', end = '2021-12-31', parameterCd = '00060') # mean daily ft3/s \n",
    "    streamflow_df.reset_index(inplace=True)\n",
    "    # commented out below because we will use estimated values as well for gap-free time series \n",
    "    # also only using gages with no missing data, so no need to drop na's \n",
    "    #streamflow = streamflow_df[streamflow_df['00060_Mean_cd'] == 'A']\n",
    "    #streamflow_df.dropna(subset=['00060_Mean'])\n",
    "    #streamflow = streamflow.reset_index(drop=True)\n",
    "    streamflow = streamflow_df[[\"datetime\", \"00060_Mean\"]]\n",
    "    streamflow.columns = [\"Date\", \"originalQ\"] # mean daily ft3/s \n",
    "\n",
    "    # Convert from ft3/s to mm/day \n",
    "    area_m2 = sbr_ref_combo_diss[sbr_ref_combo_diss['GAGE_ID'] == site].AREA.iloc[0] # m2 \n",
    "    m2_to_ft2 = 10.7639\n",
    "    ft_to_mm = 304.8\n",
    "    s_to_day = 60*60*24\n",
    "    convert= ((ft_to_mm * s_to_day) / (area_m2 * m2_to_ft2))\n",
    "    streamflow['originalQ'] = streamflow['originalQ'].multiply(convert)\n",
    "\n",
    "   \n",
    "    # calculate dQ and Q \n",
    "    streamflow['dQ'] = streamflow['originalQ'].diff()\n",
    "    # Calculate Q = Qi + Qi-1 / 2 (matches dQ time steps)\n",
    "    streamflow['Q'] = (streamflow['originalQ'] + (streamflow['originalQ'] + streamflow['dQ'].multiply(-1)))/2\n",
    "    streamflow = streamflow.reset_index(drop=True)\n",
    "\n",
    "    # Calculate time-scaled dQ and Q \n",
    "    dQ_ts = [np.nan]\n",
    "    Q_ts = [np.nan]\n",
    "    for i in range(1, streamflow.shape[0]):\n",
    "        q_diff = streamflow['originalQ'].iloc[i] - streamflow['originalQ'].iloc[i-1]\n",
    "        q = np.sum(streamflow['originalQ'].iloc[(i-1):(i +1)])/2\n",
    "        if abs(q_diff) >= (w*C):\n",
    "            dQ_ts.append(q_diff)\n",
    "            Q_ts.append(q)\n",
    "            continue\n",
    "    \n",
    "        steps = 1\n",
    "        if abs(q_diff) < (w*C):\n",
    "            for j in range(0, i):\n",
    "                steps +=1\n",
    "                q_diff_again = streamflow['originalQ'].iloc[i] - streamflow['originalQ'].iloc[i-steps]\n",
    "                if abs(q_diff_again) < (w*C):\n",
    "                    continue\n",
    "                else: \n",
    "                    #dQ_ts.append(q_diff_again/(steps))\n",
    "                    #Q_ts.append(np.sum(streamflow['originalQ'].iloc[(i-steps):(i+1)])/(steps))\n",
    "                    date_i = streamflow['Date'].iloc[i]\n",
    "                    date_old = streamflow['Date'].iloc[(i-steps)]\n",
    "                    date_diff = date_i - date_old\n",
    "                    delta = date_diff.days\n",
    "                    dQ_ts.append(q_diff_again/delta)\n",
    "                    Q_ts.append(np.sum(streamflow['originalQ'].iloc[(i-steps):(i+1)])/(delta))\n",
    "                    break\n",
    "    \n",
    "    streamflow['dQ_ts'] = dQ_ts\n",
    "    streamflow['Q_ts'] = Q_ts\n",
    "\n",
    "    # calculate absolute value of change in dQ\n",
    "    streamflow['dQdQ'] = streamflow['dQ_ts'].abs().diff()\n",
    "\n",
    "    # drop non-consecutive dates because that will have an incorrect difference \n",
    "    streamflow['day_before'] = pd.concat([pd.Series([np.nan]), streamflow['Date'].iloc[0:(streamflow.shape[0]-1)].add(timedelta(days=1))]).to_list()\n",
    "    streamflow = streamflow[(streamflow['Date'] == streamflow['day_before'])]\n",
    "    streamflow = streamflow.drop(['day_before'], axis=1)\n",
    "\n",
    "    # identify recession events \n",
    "    days_to_remove = ( (streamflow['dQ_ts'] >= 0) |   # removes days of non decreasing flow - switch to the threshold\n",
    "                    (streamflow['Q_ts'] <= 0) |   # remove days of 0 streamflow\n",
    "                    (streamflow['dQdQ'] >= 0)  # remove days where the absolute value of the derivate is not decreasing \n",
    "                    )\n",
    "    decreasing_streamflow = streamflow[-days_to_remove]   \n",
    "\n",
    "    # Individual events must be at least 5 consecutive days \n",
    "    # Remove the first day of each event\n",
    "    # loop through and increase the counter for every time there is a consevutive date and put that counter in the index for every loop \n",
    "    counting_days = []\n",
    "    consecutive = 0\n",
    "    for i in range(0, (decreasing_streamflow.shape[0]-1)):\n",
    "        if i == 0:\n",
    "            date = decreasing_streamflow['Date'].iloc[i]\n",
    "            date_next = decreasing_streamflow['Date'].iloc[i+1]\n",
    "            if (date+timedelta(days=1)) == date_next:\n",
    "                consecutive += 1\n",
    "            else: \n",
    "                consecutive = 0\n",
    "            counting_days.append(consecutive)\n",
    "    \n",
    "        if i >0:\n",
    "            date = decreasing_streamflow['Date'].iloc[i]\n",
    "            date_next = decreasing_streamflow['Date'].iloc[i+1]\n",
    "            date_prior = decreasing_streamflow['Date'].iloc[i-1]\n",
    "\n",
    "            if (date+timedelta(days=1)) == date_next:\n",
    "                consecutive += 1\n",
    "                counting_days.append(consecutive)  \n",
    "            elif ( (date+timedelta(days=1) != date_next) & (date-timedelta(days=1) == date_prior)):\n",
    "                consecutive += 1\n",
    "                counting_days.append(consecutive)  \n",
    "                consecutive = 0\n",
    "            else: \n",
    "                consecutive =0\n",
    "                counting_days.append(consecutive)      \n",
    "\n",
    "    decreasing_streamflow['consec_days'] = counting_days + [np.nan]   \n",
    "    decreasing_streamflow = decreasing_streamflow.reset_index(drop=True)\n",
    "\n",
    "    # find the events that are at least 5 days long \n",
    "    idx_gte5 = decreasing_streamflow[decreasing_streamflow['consec_days']>=5].index.tolist()\n",
    "    idx_1 = decreasing_streamflow[decreasing_streamflow['consec_days']==1].index.tolist()\n",
    "\n",
    "    K = 0\n",
    "    for upper_idx in idx_gte5:\n",
    "        K += 1\n",
    "        met_condition = [j for j in idx_1 if j<upper_idx ]\n",
    "        lower_idx = met_condition[len(met_condition)-1]\n",
    "        if K == 1:\n",
    "            keep_idx = list(range(lower_idx, upper_idx+1))\n",
    "        else:\n",
    "            keep_idx = keep_idx + list(range(lower_idx, upper_idx+1))\n",
    "    \n",
    "    final_idx = np.unique(keep_idx)\n",
    "    recessions = decreasing_streamflow.iloc[final_idx]\n",
    "    recessions = recessions.reset_index(drop=True)\n",
    "\n",
    "    # drop the first day of each recession \n",
    "    recessions = recessions[recessions['consec_days'] != 1]\n",
    "\n",
    "    # subset to the months of interest (june - august)\n",
    "    recessions = recessions.loc[recessions['Date'].dt.month.isin([5,6,7,8,9])]\n",
    "\n",
    "    # label each individual event\n",
    "    event_number = []\n",
    "    event_counter = 0\n",
    "    for i in range(0, recessions.shape[0]):\n",
    "        if i == 0:\n",
    "            event_counter = 1\n",
    "            event_number.append(event_counter)\n",
    "        else: \n",
    "            if recessions['consec_days'].iloc[i] > recessions['consec_days'].iloc[i-1]:\n",
    "                event_counter = event_counter + 0\n",
    "                event_number.append(event_counter)\n",
    "            else:\n",
    "                event_counter = event_counter + 1\n",
    "                event_number.append(event_counter)\n",
    "\n",
    "    recessions['event_number'] = event_number\n",
    "\n",
    "    # take the log transform of Q and dQ \n",
    "    recessions['log_dQ']=np.log10(recessions['dQ_ts'].abs()) # make sure to take the log of the absolute value of dQ\n",
    "    recessions['log_Q']=np.log10(recessions['Q_ts'])\n",
    "    \n",
    "    return recessions\n",
    "\n",
    "\n",
    "\n",
    "def calculate_coef(df, gage, reg_type):\n",
    "    start_year = df.Date.iloc[0].year\n",
    "    if reg_type == \"OLS\":\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df.log_Q, df.log_dQ)\n",
    "        b_val = slope\n",
    "        medEvSlope = np.median(b_val)\n",
    "        df['log_dQ_offset'] = df.log_dQ - (df.log_Q * medEvSlope)\n",
    "        a_val = np.mean(df.log_dQ_offset)\n",
    "        return {'Gage':gage, 'Year':start_year, 'A':a_val, 'B':b_val}\n",
    "    if reg_type == \"RMA\":\n",
    "        results = regress2(df.log_Q, df.log_dQ, _method_type_2=\"reduced major axis\")\n",
    "        b_val = results['slope']\n",
    "        medEvSlope = np.median(b_val)\n",
    "        df['log_dQ_offset'] = df.log_dQ - (df.log_Q * medEvSlope)\n",
    "        a_val = np.mean(df.log_dQ_offset)\n",
    "        return {'Gage': gage, 'Year':start_year, 'A':a_val, 'B':b_val}\n",
    "\n",
    "\n",
    "\n",
    "def rolling(df, gage, reg_type, interval):\n",
    "\n",
    "    # make a list of start and end years for each interval \n",
    "    start_year = df.Date.iloc[0].year\n",
    "    end_year = df.Date.iloc[df.shape[0]-1].year\n",
    "    starts = range(start_year, end_year + 2 - interval)\n",
    "    ends = [x + (interval-1) for x in starts]\n",
    "\n",
    "    # loop through each interval \n",
    "    coefficients = []\n",
    "    for i in range(0, len(starts)):\n",
    "        start = starts[i]\n",
    "        end = ends[i]\n",
    "        df_sub = df.loc[df['Date'].dt.year.isin(range(start, end + 1))]\n",
    "        if df_sub.shape[0] == 0: \n",
    "            continue\n",
    "        df_sub = df_sub.reset_index(drop=True)\n",
    "        coefficients.append(calculate_coef(df_sub, gage, reg_type))\n",
    "    \n",
    "    return pd.DataFrame(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first subset the reference watersheds to those with no missing data \n",
    "def check_streamflow(site):\n",
    "    \n",
    "    # quality control \n",
    "    # A = Approved for publication \n",
    "    # P = Provisional data subject to revision \n",
    "    # e = Value has been estimated \n",
    "\n",
    "    streamflow_df = nwis.get_record(sites=site, service = 'dv', start = '1900-01-01', parameterCd = '00060')\n",
    "    if streamflow_df.shape[0] == 0:\n",
    "        return np.nan\n",
    "    date_index = streamflow_df.index.to_series().between('1984-01-01', '2021-12-31')\n",
    "    streamflow_subset = streamflow_df[date_index]\n",
    "    #streamflow_subset = streamflow_subset[streamflow_subset['00060_Mean_cd'] == 'A']\n",
    "    streamflow_subset.dropna(subset=['00060_Mean'])\n",
    "    streamflow = streamflow_subset.reset_index(drop=True)\n",
    "    # I want to use the estimated values because we can't have gaps \n",
    "\n",
    "    sdate = date(1984, 1, 1)\n",
    "    edate = date(2021, 12, 31)\n",
    "    delta = edate-sdate\n",
    "    total_days = delta.days + 1\n",
    "    \n",
    "    pct_missing = (streamflow_subset.shape[0]/total_days)*100\n",
    "    \n",
    "    return pct_missing\n",
    "\n",
    "\n",
    "pct_miss= []\n",
    "for gage_id in sbr_ref_combo_diss['GAGE_ID']:\n",
    "    pct_miss.append(check_streamflow(gage_id))\n",
    "sbr_ref_combo_diss['pct_stream'] = pct_miss\n",
    "\n",
    "sbr_ref_combo_diss_100 = sbr_ref_combo_diss[sbr_ref_combo_diss['pct_stream'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02053800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['originalQ'] = streamflow['originalQ'].multiply(convert)\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['dQ'] = streamflow['originalQ'].diff()\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  decreasing_streamflow['consec_days'] = counting_days + [np.nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02056900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['originalQ'] = streamflow['originalQ'].multiply(convert)\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['dQ'] = streamflow['originalQ'].diff()\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  decreasing_streamflow['consec_days'] = counting_days + [np.nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02069700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['originalQ'] = streamflow['originalQ'].multiply(convert)\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['dQ'] = streamflow['originalQ'].diff()\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  decreasing_streamflow['consec_days'] = counting_days + [np.nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02070000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['originalQ'] = streamflow['originalQ'].multiply(convert)\n",
      "/var/folders/6_/17bx0qz13sjdf13yymjj7kb00000gn/T/ipykernel_69616/409050222.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  streamflow['dQ'] = streamflow['originalQ'].diff()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (13876) does not match length of index (13880)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/GoogleDrive/My Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m sbr_ref_combo_diss_100\u001b[39m.\u001b[39mGAGE_ID:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000005?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mid\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000005?line=5'>6</a>\u001b[0m     df \u001b[39m=\u001b[39m create_recession_df(\u001b[39mid\u001b[39;49m, w\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, C\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000005?line=6'>7</a>\u001b[0m     coefs_overall \u001b[39m=\u001b[39m calculate_coef(df, \u001b[39mid\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRMA\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000005?line=8'>9</a>\u001b[0m     coefs_3r \u001b[39m=\u001b[39m rolling(df, \u001b[39mid\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRMA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "\u001b[1;32m/Volumes/GoogleDrive/My Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb Cell 3'\u001b[0m in \u001b[0;36mcreate_recession_df\u001b[0;34m(gage, w, C)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000003?line=59'>60</a>\u001b[0m                 Q_ts\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msum(streamflow[\u001b[39m'\u001b[39m\u001b[39moriginalQ\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[(i\u001b[39m-\u001b[39msteps):(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)])\u001b[39m/\u001b[39m(delta))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000003?line=60'>61</a>\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000003?line=62'>63</a>\u001b[0m streamflow[\u001b[39m'\u001b[39m\u001b[39mdQ_ts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dQ_ts\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000003?line=63'>64</a>\u001b[0m streamflow[\u001b[39m'\u001b[39m\u001b[39mQ_ts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m Q_ts\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Chapter2_mechanisms_forest_water_cycling/Scripts/baseflow_recession_threshold.ipynb#ch0000003?line=65'>66</a>\u001b[0m \u001b[39m# calculate absolute value of change in dQ\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3651'>3652</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3652'>3653</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3653'>3654</a>\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3654'>3655</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3821'>3822</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3822'>3823</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3823'>3824</a>\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3824'>3825</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3829'>3830</a>\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3830'>3831</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3831'>3832</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3833'>3834</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3834'>3835</a>\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3835'>3836</a>\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3836'>3837</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3837'>3838</a>\u001b[0m     ):\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3838'>3839</a>\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=3839'>3840</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=4531'>4532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=4533'>4534</a>\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=4534'>4535</a>\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/frame.py?line=4535'>4536</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=552'>553</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=553'>554</a>\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=554'>555</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=555'>556</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=556'>557</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=557'>558</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=558'>559</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=559'>560</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=560'>561</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/katiemcquillan/opt/anaconda3/envs/ch2-python-env/lib/python3.9/site-packages/pandas/core/common.py?line=561'>562</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (13876) does not match length of index (13880)"
     ]
    }
   ],
   "source": [
    "# dataframe with the overall A and B and the slope + pvalue for A and B \n",
    "\n",
    "row_list = []\n",
    "for id in sbr_ref_combo_diss_100.GAGE_ID:\n",
    "    print(id)\n",
    "    df = create_recession_df(id, w=0.1, C=3)\n",
    "    coefs_overall = calculate_coef(df, id, 'RMA')\n",
    "\n",
    "    coefs_3r = rolling(df, id, 'RMA', 3)\n",
    "    # linear regression \n",
    "    #slope_A, intercept_A, r_value_A, p_value_A, std_err_A = stats.linregress(coefs_3r.Year, coefs_3r.A)\n",
    "    #slope_B, intercept_B, r_value_B, p_value_B, std_err_B = stats.linregress(coefs_3r.Year, coefs_3r.B)\n",
    "\n",
    "    # sens slope + mann kendall \n",
    "    mks_A = mk.original_test(coefs_3r['A'])\n",
    "    p_value_A = mks_A[2] # p-value \n",
    "    slope_A = mks_A[7] # Theil-Sen estimator/slope \n",
    "\n",
    "    mks_B = mk.original_test(coefs_3r['B'])\n",
    "    p_value_B = mks_B[2] # p-value \n",
    "    slope_B = mks_B[7] # Theil-Sen estimator/slope \n",
    "\n",
    "    row_list.append({'gage':id, 'A':coefs_overall['A'],'B':coefs_overall['B'], 'slope_A':slope_A, 'pvalue_A':p_value_A, 'slope_B':slope_B, 'pvalue_B':p_value_B})\n",
    "\n",
    "recession_results = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>slope_A</th>\n",
       "      <th>pvalue_A</th>\n",
       "      <th>slope_B</th>\n",
       "      <th>pvalue_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02053800</td>\n",
       "      <td>-0.975812</td>\n",
       "      <td>1.833820</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.177508</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>0.018452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03463300</td>\n",
       "      <td>-1.357076</td>\n",
       "      <td>1.801764</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.375964</td>\n",
       "      <td>-0.014926</td>\n",
       "      <td>0.042406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>03473000</td>\n",
       "      <td>-1.084261</td>\n",
       "      <td>2.155996</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.024611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>03498500</td>\n",
       "      <td>-1.086449</td>\n",
       "      <td>1.920233</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.032478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>03500000</td>\n",
       "      <td>-1.575810</td>\n",
       "      <td>2.055720</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>0.838109</td>\n",
       "      <td>-0.025441</td>\n",
       "      <td>0.004809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gage         A         B   slope_A  pvalue_A   slope_B  pvalue_B\n",
       "0   02053800 -0.975812  1.833820  0.003227  0.177508 -0.011313  0.018452\n",
       "20  03463300 -1.357076  1.801764  0.003446  0.375964 -0.014926  0.042406\n",
       "23  03473000 -1.084261  2.155996 -0.002699  0.062033  0.009654  0.024611\n",
       "25  03498500 -1.086449  1.920233 -0.000532  0.733463  0.008177  0.032478\n",
       "26  03500000 -1.575810  2.055720 -0.000425  0.838109 -0.025441  0.004809"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recession_results[recession_results['pvalue_B'] <= 0.05]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7e9e3ed62266d3386b0937140899a88d3a70dd81de793411d23e0292bf7f0bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ch2-python-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
